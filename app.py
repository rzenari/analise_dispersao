# ==============================================================================
# 1. IMPORTA√á√ÉO DAS BIBLIOTECAS
# ==============================================================================
import streamlit as st
import pandas as pd
import geopandas as gpd
import numpy as np
from sklearn.cluster import DBSCAN, KMeans
from scipy.spatial import cKDTree
from math import sqrt, ceil
import folium
from streamlit_folium import st_folium
from folium.plugins import MarkerCluster
from shapely.geometry import Polygon
import io
import os
import glob
import zipfile
import requests
from datetime import datetime

# ==============================================================================
# 2. CONFIGURA√á√ÉO DA P√ÅGINA E T√çTULOS
# ==============================================================================
st.set_page_config(layout="wide", page_title="An√°lise de Dispers√£o Geogr√°fica")

st.title("üó∫Ô∏è Ferramenta de An√°lise de Dispers√£o Geogr√°fica")
st.write("Fa√ßa o upload da sua planilha de cortes para analisar a distribui√ß√£o geogr√°fica e identificar clusters")

# ==============================================================================
# 3. FUN√á√ïES DE AN√ÅLISE
# ==============================================================================

@st.cache_data
def carregar_kmls(pasta_projeto):
    """
    Varre a pasta, l√™ arquivos .kml e .kmz, corrige geometrias inv√°lidas
    e retorna um dicion√°rio de geometrias individuais e um log de depura√ß√£o.
    """
    kml_files = glob.glob(os.path.join(pasta_projeto, '*.kml'))
    kmz_files = glob.glob(os.path.join(pasta_projeto, '*.kmz'))
    all_gis_files = kml_files + kmz_files

    if not all_gis_files:
        return None, pd.DataFrame([{'Arquivo': 'Nenhum arquivo .kml ou .kmz encontrado', 'Status': 'N/A'}])
    
    debug_log = []
    geometrias_individuais = {}
    
    for gis_file in all_gis_files:
        nome_arquivo = os.path.basename(gis_file)
        try:
            gdf_file = None
            if gis_file.lower().endswith('.kml'):
                gdf_file = gpd.read_file(gis_file, driver='KML')
            elif gis_file.lower().endswith('.kmz'):
                with zipfile.ZipFile(gis_file, 'r') as z:
                    kml_filename = next((name for name in z.namelist() if name.lower().endswith('.kml')), None)
                    if kml_filename:
                        with z.open(kml_filename) as kml_content:
                            gdf_file = gpd.read_file(kml_content, driver='KML')
            
            if gdf_file is None or gdf_file.empty:
                debug_log.append({'Arquivo': nome_arquivo, 'Status': '‚ö†Ô∏è Aviso', 'Erro': 'Nenhum pol√≠gono encontrado.'})
                continue

            gdf_file = gdf_file[gdf_file.geometry.type.isin(['Polygon', 'MultiPolygon'])]
            
            geometrias_corrigidas = []
            for poligono in gdf_file.geometry:
                if not poligono.is_valid:
                    poligono_corrigido = poligono.buffer(0)
                    if poligono_corrigido.is_valid and not poligono_corrigido.is_empty:
                        geometrias_corrigidas.append(poligono_corrigido)
                else:
                    geometrias_corrigidas.append(poligono)
            
            if geometrias_corrigidas:
                geometrias_individuais[nome_arquivo] = gpd.GeoSeries(geometrias_corrigidas).unary_union
                debug_log.append({'Arquivo': nome_arquivo, 'Status': '‚úÖ Sucesso'})
            else:
                debug_log.append({'Arquivo': nome_arquivo, 'Status': '‚ùå Falha', 'Erro': 'Geometria inv√°lida, n√£o foi poss√≠vel corrigir.'})

        except Exception as e:
            debug_log.append({'Arquivo': nome_arquivo, 'Status': '‚ùå Falha', 'Erro': str(e)})

    if not geometrias_individuais:
        return None, pd.DataFrame(debug_log)

    return geometrias_individuais, pd.DataFrame(debug_log)


def carregar_dados_completos(arquivo_enviado):
    """L√™ o arquivo completo com todas as colunas."""
    arquivo_enviado.seek(0)
    
    def processar_dataframe(df):
        df.columns = df.columns.str.lower().str.strip()
        if 'latitude' not in df.columns or 'longitude' not in df.columns:
            st.error("ERRO: Colunas 'latitude' e/ou 'longitude' n√£o foram encontradas."); st.write("Colunas encontradas:", df.columns.tolist())
            return None
        df['latitude'] = df['latitude'].astype(str).str.replace(',', '.').astype(float)
        df['longitude'] = df['longitude'].astype(str).str.replace(',', '.').astype(float)
        df = df.dropna(subset=['latitude', 'longitude'])
        return df

    try:
        df = pd.read_csv(arquivo_enviado, encoding='utf-16', sep='\t')
        st.success("Arquivo CSV de cortes lido com sucesso (codifica√ß√£o: utf-16)."); return processar_dataframe(df)
    except Exception:
        try:
            arquivo_enviado.seek(0)
            df = pd.read_csv(arquivo_enviado, encoding='latin-1', sep=None, engine='python')
            st.success("Arquivo CSV de cortes lido com sucesso (codifica√ß√£o: latin-1)."); return processar_dataframe(df)
        except Exception:
            try:
                arquivo_enviado.seek(0)
                df = pd.read_excel(arquivo_enviado, engine='openpyxl')
                st.success("Arquivo Excel de cortes lido com sucesso."); return processar_dataframe(df)
            except Exception as e:
                st.error(f"N√£o foi poss√≠vel ler o arquivo de cortes. √öltimo erro: {e}"); return None

def carregar_dados_metas(arquivo_metas):
    """L√™ o arquivo opcional de metas e equipes."""
    if arquivo_metas is None:
        return None
    arquivo_metas.seek(0)
    try:
        df = pd.read_excel(arquivo_metas, engine='openpyxl')
        df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')
        required_cols = ['centro_operativo', 'equipes', 'servi√ßos_designados', 'produ√ß√£o', 'meta_di√°ria']
        if all(col in df.columns for col in required_cols):
            df['centro_operativo'] = df['centro_operativo'].str.strip().str.upper()
            return df
        else:
            st.error(f"ERRO: A planilha de metas precisa conter as colunas: {', '.join(required_cols)}.")
            return None
    except Exception as e:
        st.error(f"N√£o foi poss√≠vel ler a planilha de metas. Erro: {e}")
        return None

def executar_dbscan(gdf, eps_km=0.5, min_samples=3):
    """Executa o DBSCAN para encontrar clusters."""
    if gdf.empty or len(gdf) < min_samples: 
        gdf['cluster'] = -1
        return gdf
    
    gdf_copy = gdf.copy()
    raio_terra_km = 6371; eps_rad = eps_km / raio_terra_km
    coords = np.radians(gdf_copy[['latitude', 'longitude']].values)
    db = DBSCAN(eps=eps_rad, min_samples=min_samples, algorithm='ball_tree', metric='haversine').fit(coords)
    gdf_copy['cluster'] = db.labels_
    return gdf_copy

def simular_pacotes_por_densidade(gdf_co, n_equipes, capacidade_designada):
    """
    Simula pacotes com base na densidade, respeitando estritamente a capacidade de servi√ßos designados.
    """
    if gdf_co.empty or n_equipes == 0 or capacidade_designada == 0:
        return gpd.GeoDataFrame(), gdf_co.copy()

    gdf_clusters_reais = gdf_co.copy()
    pacotes_candidatos = []
    
    for cluster_id in gdf_clusters_reais['cluster'].unique():
        if cluster_id == -1: continue
        gdf_cluster_atual = gdf_clusters_reais[gdf_clusters_reais['cluster'] == cluster_id]
        contagem = len(gdf_cluster_atual)

        if 0 < contagem <= capacidade_designada:
            pacotes_candidatos.append({'indices': gdf_cluster_atual.index, 'pontos': gdf_cluster_atual})
        
        elif contagem > capacidade_designada:
            gdf_temp = gdf_cluster_atual.copy()
            while len(gdf_temp) > 0:
                if len(gdf_temp) <= capacidade_designada:
                    pacotes_candidatos.append({'indices': gdf_temp.index, 'pontos': gdf_temp})
                    break
                
                coords_temp = gdf_temp[['longitude', 'latitude']].values
                tree = cKDTree(coords_temp)
                
                _, indices_vizinhos = tree.query(coords_temp[0], k=min(capacidade_designada, len(coords_temp)))
                
                indices_reais_no_gdf_temp = gdf_temp.index[indices_vizinhos]
                sub_pacote = gdf_temp.loc[indices_reais_no_gdf_temp]
                
                pacotes_candidatos.append({'indices': sub_pacote.index, 'pontos': sub_pacote})
                
                gdf_temp.drop(indices_reais_no_gdf_temp, inplace=True)

    pacotes_ranqueados = []
    for candidato in pacotes_candidatos:
        pontos = candidato['pontos']
        contagem = len(pontos)
        if contagem > 0:
            try:
                hull = pontos.unary_union.convex_hull
                area_km2 = (gpd.GeoDataFrame(geometry=[hull], crs="EPSG:4326").to_crs("EPSG:3857").geometry.area / 1_000_000).iloc[0]
                densidade = contagem / area_km2 if area_km2 > 0 else 0
                
                candidato['contagem'] = contagem
                candidato['area_km2'] = round(area_km2, 2)
                candidato['densidade'] = round(densidade, 2)
                pacotes_ranqueados.append(candidato)
            except Exception:
                continue

    pacotes_ranqueados.sort(key=lambda p: p['densidade'], reverse=True)
    pacotes_vencedores = pacotes_ranqueados[:n_equipes]
    
    indices_alocados = []
    gdf_co['pacote_id'] = -1 
    for i, pacote in enumerate(pacotes_vencedores):
        gdf_co.loc[pacote['indices'], 'pacote_id'] = i
        indices_alocados.extend(pacote['indices'])

    gdf_alocados = gdf_co.loc[indices_alocados].copy()
    gdf_excedentes = gdf_co.drop(indices_alocados).copy()

    return gdf_alocados, gdf_excedentes

def calcular_qualidade_carteira(row):
    """Calcula a qualidade da carteira com base nas metas e servi√ßos agrupados."""
    meta_diaria = row.get('meta_di√°ria', 0)
    if pd.isna(meta_diaria) or meta_diaria == 0: return "Sem Meta"
    n_agrupados = row.get('Agrupado', 0)
    total_servicos = row.get('total', 0)
    
    if n_agrupados >= meta_diaria: return "‚úÖ √ìtima"
    elif total_servicos >= meta_diaria: return "‚ö†Ô∏è Aten√ß√£o"
    else: return "‚ùå Cr√≠tica"

def df_to_excel(df):
    """Converte um DataFrame para um objeto BytesIO em formato Excel."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Dados')
    return output.getvalue()

@st.cache_data(ttl=10800)
def get_weather_forecast(lat, lon, api_key):
    """Busca a previs√£o de 5 dias da API OpenWeatherMap."""
    URL = f"https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={api_key}&units=metric&lang=pt_br"
    try:
        response = requests.get(URL)
        response.raise_for_status()
        data = response.json()
        
        daily_forecasts = {}
        for forecast in data['list']:
            date = datetime.fromtimestamp(forecast['dt']).strftime('%Y-%m-%d')
            # Prioriza a previs√£o do meio-dia para representar o dia
            if date not in daily_forecasts or forecast['dt_txt'].endswith('12:00:00'):
                daily_forecasts[date] = forecast
        
        forecast_list = []
        for date, forecast in sorted(daily_forecasts.items())[:5]:
            forecast_list.append({
                "date": datetime.strptime(date, '%Y-%m-%d').strftime('%d/%m'),
                "condition": forecast['weather'][0]['description'].title(),
                "icon": f"https://openweathermap.org/img/wn/{forecast['weather'][0]['icon']}@2x.png",
                "wind_speed_kmh": round(forecast['wind']['speed'] * 3.6, 1)
            })
        return forecast_list
    except requests.exceptions.RequestException as e:
        return f"Erro ao buscar dados: {e}"

def get_operational_status(condition, wind_speed):
    """Define o status da opera√ß√£o com base no clima."""
    is_rainy = any(keyword in condition.lower() for keyword in ["chuva", "tempestade", "chuvisco"])
    is_windy = wind_speed > 40.0
    
    if is_rainy or is_windy:
        return "‚ö†Ô∏è Poss√≠vel Conting√™ncia"
    else:
        return "‚úÖ Opera√ß√£o Normal"
        
# ==============================================================================
# 4. L√ìGICA PRINCIPAL DA APLICA√á√ÉO
# ==============================================================================
st.sidebar.header("Controles")
uploaded_file = st.sidebar.file_uploader("1. Escolha a planilha de cortes", type=["csv", "xlsx", "xls"])
metas_file = st.sidebar.file_uploader("2. Escolha a planilha de metas (Opcional)", type=["xlsx", "xls"])

if uploaded_file is not None:
    df_completo_original = carregar_dados_completos(uploaded_file)
    df_metas = carregar_dados_metas(metas_file)
    
    if df_completo_original is not None:
        st.sidebar.success(f"{len(df_completo_original)} registros carregados!")
        
        geometrias_kml_dict, kml_debug_log = carregar_kmls('.')
        if kml_debug_log is not None:
            sucesso_count = (kml_debug_log['Status'] == '‚úÖ Sucesso').sum()
            st.sidebar.info(f"{sucesso_count} arquivo(s) KML/KMZ carregado(s) com sucesso.")
            with st.sidebar.expander("üîç Depurador de Arquivos KML/KMZ"):
                st.dataframe(kml_debug_log)
        
        if df_metas is not None: 
            st.sidebar.info(f"Metas carregadas para {len(df_metas)} COs.")

        areas_sem_laranja = []
        if geometrias_kml_dict:
            st.sidebar.markdown("### Controle da √Årea Laranja")
            nomes_areas = list(geometrias_kml_dict.keys())
            areas_sem_laranja = st.sidebar.multiselect('Desativar √Årea Laranja para:', nomes_areas, help="Selecione as √°reas de risco que N√ÉO devem ter a √°rea laranja de 120m ao redor.")

        kml_risco_unificado, kml_laranja_unificado = None, None
        if geometrias_kml_dict:
            kml_risco_unificado = gpd.GeoSeries(list(geometrias_kml_dict.values()), crs="EPSG:4326").unary_union
            
            poligonos_para_buffer = [poly for name, poly in geometrias_kml_dict.items() if name not in areas_sem_laranja]
            if poligonos_para_buffer:
                geometria_para_buffer = gpd.GeoSeries(poligonos_para_buffer, crs="EPSG:4326").unary_union
                geometria_proj = gpd.GeoSeries([geometria_para_buffer], crs="EPSG:4326").to_crs("EPSG:3857")
                buffer_grande = geometria_proj.buffer(120)
                geometria_laranja_proj = buffer_grande.difference(geometria_proj)
                kml_laranja_unificado = gpd.GeoSeries(geometria_laranja_proj, crs="EPSG:3857").to_crs("EPSG:4326").unary_union

        st.sidebar.markdown("### Filtros da An√°lise")
        filtros = ['sucursal', 'centro_operativo', 'corte_recorte', 'prioridade']
        valores_selecionados = {}
        for coluna in filtros:
            if coluna in df_completo_original.columns:
                lista_unica = df_completo_original[coluna].dropna().unique().tolist()
                opcoes = sorted([str(item) for item in lista_unica])
                if coluna == 'prioridade':
                    valores_selecionados[coluna] = st.sidebar.multiselect(f"{coluna.replace('_', ' ').title()}", opcoes)
                else:
                    valores_selecionados[coluna] = st.sidebar.selectbox(f"{coluna.replace('_', ' ').title()}", ["Todos"] + opcoes)

        df_filtrado = df_completo_original.copy()
        for coluna, valor in valores_selecionados.items():
            if coluna in df_filtrado.columns:
                if coluna == 'prioridade':
                    if valor: df_filtrado = df_filtrado[df_filtrado[coluna].astype(str).isin(valor)]
                elif valor != "Todos": df_filtrado = df_filtrado[df_filtrado[coluna].astype(str) == valor]

        gdf_filtrado_base = gpd.GeoDataFrame(
            df_filtrado, 
            geometry=gpd.points_from_xy(df_filtrado.longitude, df_filtrado.latitude), 
            crs="EPSG:4326"
        )

        gdf_filtrado_base['classificacao'] = 'A ser definido'
        gdf_risco, gdf_laranja = gpd.GeoDataFrame(), gpd.GeoDataFrame()

        if kml_risco_unificado is not None:
            indices_risco = gdf_filtrado_base.within(kml_risco_unificado)
            gdf_filtrado_base.loc[indices_risco, 'classificacao'] = '√Årea de Risco'
            gdf_risco = gdf_filtrado_base[indices_risco].copy()

        if kml_laranja_unificado is not None and not kml_laranja_unificado.is_empty:
            gdf_temp_para_laranja = gdf_filtrado_base[gdf_filtrado_base['classificacao'] == 'A ser definido']
            indices_laranja = gdf_temp_para_laranja.within(kml_laranja_unificado)
            gdf_filtrado_base.loc[indices_laranja[indices_laranja].index, 'classificacao'] = '√Årea Laranja'
            gdf_laranja = gdf_filtrado_base[gdf_filtrado_base['classificacao'] == '√Årea Laranja'].copy()

        gdf_para_analise = gdf_filtrado_base[gdf_filtrado_base['classificacao'] == 'A ser definido'].copy()
        
        st.sidebar.markdown("### Par√¢metros de Cluster")
        eps_cluster_km = st.sidebar.slider("Raio do Cluster (km)", 0.1, 5.0, 1.0, 0.1)
        min_samples_cluster = st.sidebar.slider("M√≠nimo de Pontos por Cluster", 2, 20, 20, 1)

        if not gdf_para_analise.empty:
            gdf_com_clusters = executar_dbscan(gdf_para_analise, eps_km=eps_cluster_km, min_samples=min_samples_cluster)
            gdf_filtrado_base.loc[gdf_com_clusters[gdf_com_clusters['cluster'] != -1].index, 'classificacao'] = 'Agrupado'
            gdf_filtrado_base.loc[gdf_com_clusters[gdf_com_clusters['cluster'] == -1].index, 'classificacao'] = 'Disperso'
            gdf_filtrado_base = gdf_filtrado_base.merge(gdf_com_clusters[['cluster']], left_index=True, right_index=True, how='left')
        else:
             gdf_filtrado_base['cluster'] = -1
        
        gdf_filtrado_base['cluster'] = gdf_filtrado_base['cluster'].fillna(-1)
        gdf_filtrado_base.loc[gdf_filtrado_base['classificacao'] == 'A ser definido', 'classificacao'] = 'Disperso'

        gdf_alocados_final = gpd.GeoDataFrame()
        if df_metas is not None:
            todos_alocados, todos_excedentes = [], []
            gdf_para_pacotes = gdf_filtrado_base[gdf_filtrado_base['classificacao'] == 'Agrupado'].copy()
            cos_filtrados = gdf_para_pacotes['centro_operativo'].unique() if not gdf_para_pacotes.empty else []
            for co in cos_filtrados:
                gdf_co = gdf_para_pacotes[gdf_para_pacotes['centro_operativo'] == co].copy()
                metas_co = df_metas[df_metas['centro_operativo'].str.strip().str.upper() == co.strip().upper()]
                if not metas_co.empty:
                    n_equipes = int(metas_co['equipes'].iloc[0])
                    capacidade_designada = int(metas_co['servi√ßos_designados'].iloc[0])
                    if n_equipes > 0 and capacidade_designada > 0 and len(gdf_co) > 0:
                        alocados, excedentes_co = simular_pacotes_por_densidade(gdf_co, n_equipes, capacidade_designada)
                        todos_alocados.append(alocados)
                        todos_excedentes.append(excedentes_co)
                else: 
                    todos_excedentes.append(gdf_co)
            
            gdf_servicos_restantes = gdf_filtrado_base[gdf_filtrado_base['classificacao'] != 'Agrupado'].copy()
            if not gdf_servicos_restantes.empty:
                todos_excedentes.append(gdf_servicos_restantes)
            
            gdf_alocados_final = pd.concat(todos_alocados, ignore_index=True) if todos_alocados else gpd.GeoDataFrame()
            gdf_excedentes_final = pd.concat(todos_excedentes, ignore_index=True) if todos_excedentes else gpd.GeoDataFrame()
        
        st.header("Resultados da An√°lise")
        
        if not gdf_filtrado_base.empty:
            st.sidebar.markdown("### Filtro de Visualiza√ß√£o do Mapa")
            opcoes_visualizacao = ["Todos", "Agrupado", "Disperso", "√Årea de Risco", "√Årea Laranja"]
            tipo_visualizacao = st.sidebar.radio("Mostrar nos mapas:", opcoes_visualizacao)
            
            st.sidebar.markdown("### üì• Downloads")
            
            df_agrupados_download = gdf_filtrado_base[gdf_filtrado_base['classificacao'] == 'Agrupado'].drop(columns=['geometry', 'cluster'], errors='ignore')
            if not df_agrupados_download.empty:
                st.sidebar.download_button(label="‚¨áÔ∏è Baixar Agrupados (Excel)", data=df_to_excel(df_agrupados_download), file_name='servicos_agrupados.xlsx', mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
            
            df_dispersos_download = gdf_filtrado_base[gdf_filtrado_base['classificacao'] == 'Disperso'].drop(columns=['geometry', 'cluster'], errors='ignore')
            if not df_dispersos_download.empty:
                st.sidebar.download_button(label="‚¨áÔ∏è Baixar Dispersos (Excel)", data=df_to_excel(df_dispersos_download), file_name='servicos_dispersos.xlsx', mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')

            if not gdf_risco.empty:
                st.sidebar.download_button(label="‚¨áÔ∏è Baixar √Årea de Risco (Excel)", data=df_to_excel(gdf_risco), file_name='servicos_area_risco.xlsx', mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
            
            if not gdf_laranja.empty:
                st.sidebar.download_button(label="‚¨áÔ∏è Baixar √Årea Laranja (Excel)", data=df_to_excel(gdf_laranja), file_name='servicos_area_laranja.xlsx', mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
            
            if not gdf_alocados_final.empty:
                st.sidebar.download_button(
                    label="‚¨áÔ∏è Baixar Pacotes de Trabalho (Excel)",
                    data=df_to_excel(gdf_alocados_final.drop(columns=['geometry', 'cluster'], errors='ignore')),
                    file_name='pacotes_de_trabalho.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )

            gdf_visualizacao = gdf_filtrado_base.copy()
            if tipo_visualizacao != "Todos":
                 gdf_visualizacao = gdf_filtrado_base[gdf_filtrado_base['classificacao'] == tipo_visualizacao]

            lista_abas = ["üó∫Ô∏è An√°lise Geogr√°fica", "üìä Resumo por CO", "üìç Contorno dos Clusters"]
            if df_metas is not None:
                lista_abas.append("üì¶ Pacotes de Trabalho")
            lista_abas.append("üå¶Ô∏è Previs√£o do Tempo")
            lista_abas.append("üí° Metodologia")
            tabs = st.tabs(lista_abas)
            
            tab_index = 0

            with tabs[tab_index]: # An√°lise Geogr√°fica
                with st.spinner('Carregando an√°lise e mapa...'):
                    st.subheader("Resumo da An√°lise de Classifica√ß√£o")
                    
                    total_servicos = len(gdf_filtrado_base)
                    n_agrupados = len(gdf_filtrado_base[gdf_filtrado_base['classificacao'] == 'Agrupado'])
                    n_dispersos = len(gdf_filtrado_base[gdf_filtrado_base['classificacao'] == 'Disperso'])
                    n_risco = len(gdf_risco)
                    n_laranja = len(gdf_laranja)
                    
                    p_agrupados = (n_agrupados / total_servicos * 100) if total_servicos > 0 else 0
                    p_dispersos = (n_dispersos / total_servicos * 100) if total_servicos > 0 else 0
                    p_risco = (n_risco / total_servicos * 100) if total_servicos > 0 else 0
                    p_laranja = (n_laranja / total_servicos * 100) if total_servicos > 0 else 0
                    
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("N¬∫ Agrupados", f"{n_agrupados}", f"{p_agrupados:.1f}%")
                    col2.metric("N¬∫ Dispersos", f"{n_dispersos}", f"{p_dispersos:.1f}%")
                    col3.metric("N¬∫ em √Årea de Risco", f"{n_risco}", f"{p_risco:.1f}%")
                    col4.metric("N¬∫ em √Årea Laranja", f"{n_laranja}", f"{p_laranja:.1f}%")

                    st.subheader(f"Mapa Interativo")
                    if not gdf_visualizacao.empty:
                        map_center = [gdf_visualizacao.latitude.mean(), gdf_visualizacao.longitude.mean()]
                        m = folium.Map(location=map_center, zoom_start=11)
                        if geometrias_kml_dict:
                            for nome, poligono in geometrias_kml_dict.items():
                                folium.GeoJson(poligono, style_function=lambda x: {'fillColor': 'red', 'color': 'red', 'weight': 2, 'fillOpacity': 0.2}, tooltip=f"√Årea de Risco: {nome}").add_to(m)
                        
                        if kml_laranja_dict:
                            for nome, poligono in kml_laranja_dict.items():
                                if poligono and not poligono.is_empty:
                                    folium.GeoJson(poligono, style_function=lambda x: {'fillColor': 'orange', 'color': 'orange', 'weight': 2, 'fillOpacity': 0.2}, tooltip=f"√Årea Laranja: {nome}").add_to(m)
                        
                        cor_classificacao = {'Agrupado': 'blue', 'Disperso': 'gray', '√Årea de Risco': 'red', '√Årea Laranja': 'orange'}
                        for _, row in gdf_visualizacao.iterrows():
                            folium.CircleMarker(location=[row['latitude'], row['longitude']], radius=5, color=cor_classificacao.get(row['classificacao'], 'black'), fill=True, fill_color=cor_classificacao.get(row['classificacao'], 'black'), fill_opacity=0.7, popup=f"Classifica√ß√£o: {row['classificacao']}").add_to(m)
                        st_folium(m, use_container_width=True, height=700)
                    else:
                        st.warning("Nenhum servi√ßo para exibir no mapa com os filtros atuais.")
            tab_index += 1

            with tabs[tab_index]: # Resumo por CO
                with st.spinner('Gerando tabela de resumo...'):
                    st.subheader("Resumo por Centro Operativo")
                    
                    resumo_co = gdf_filtrado_base.groupby('centro_operativo')['classificacao'].value_counts().unstack(fill_value=0)
                    for col in ['Agrupado', 'Disperso', '√Årea de Risco', '√Årea Laranja']:
                        if col not in resumo_co.columns: resumo_co[col] = 0
                    
                    resumo_co['total'] = resumo_co['Agrupado'] + resumo_co['Disperso'] + resumo_co['√Årea de Risco'] + resumo_co['√Årea Laranja']
                    resumo_co['% Agrupado'] = (resumo_co['Agrupado'] / resumo_co['total'] * 100).round(1)
                    resumo_co['% Disperso'] = (resumo_co['Disperso'] / resumo_co['total'] * 100).round(1)
                    resumo_co['% √Årea de Risco'] = (resumo_co['√Årea de Risco'] / resumo_co['total'] * 100).round(1)
                    resumo_co['% √Årea Laranja'] = (resumo_co['√Årea Laranja'] / resumo_co['total'] * 100).round(1)
                    resumo_co.reset_index(inplace=True)

                    if df_metas is not None:
                        resumo_simulacao = gdf_alocados_final.groupby('centro_operativo').agg(
                            Servi√ßos_Alocados=('pacote_id', 'size'),
                            Pacotes_Criados=('pacote_id', 'nunique')
                        ).reset_index()
                        resumo_co = pd.merge(resumo_co, resumo_simulacao, on='centro_operativo', how='left')
                        
                        resumo_co['centro_operativo_join_key'] = resumo_co['centro_operativo'].str.strip().str.upper()
                        df_metas['centro_operativo_join_key'] = df_metas['centro_operativo'].str.strip().str.upper()
                        resumo_co = pd.merge(resumo_co, df_metas, on='centro_operativo_join_key', how='left')
                        
                        if 'centro_operativo_x' in resumo_co.columns:
                           resumo_co = resumo_co.drop(columns=['centro_operativo_y', 'centro_operativo_join_key']).rename(columns={'centro_operativo_x': 'centro_operativo'})
                        
                        resumo_co['Expectativa_Execu√ß√£o'] = resumo_co['equipes'] * resumo_co['produ√ß√£o']
                        resumo_co['Ader√™ncia_√†_Meta_%'] = (resumo_co['Servi√ßos_Alocados'] / resumo_co['meta_di√°ria'] * 100).fillna(0).round(1)
                        resumo_co['Ocupa√ß√£o_das_Equipes_%'] = (resumo_co['Pacotes_Criados'] / resumo_co['equipes'] * 100).fillna(0).round(1)
                        resumo_co['qualidade_da_carteira'] = resumo_co.apply(calcular_qualidade_carteira, axis=1)
                        
                        cols_ordem = ['centro_operativo', 'total', 'Agrupado', '% Agrupado', 'Disperso', '% Disperso', '√Årea de Risco', '% √Årea de Risco', '√Årea Laranja', '% √Årea Laranja', 'equipes', 'meta_di√°ria', 'Expectativa_Execu√ß√£o', 'Servi√ßos_Alocados', 'Pacotes_Criados', 'Ader√™ncia_√†_Meta_%', 'Ocupa√ß√£o_das_Equipes_%', 'qualidade_da_carteira']
                        cols_existentes = [col for col in cols_ordem if col in resumo_co.columns]
                        resumo_co = resumo_co[cols_existentes].fillna(0)

                    st.dataframe(resumo_co, use_container_width=True)
            tab_index += 1

            with tabs[tab_index]: # Contorno dos Clusters
                with st.spinner('Desenhando contornos dos clusters...'):
                    st.subheader("Contorno Geogr√°fico dos Clusters (Hotspots)")
                    st.write("Este mapa desenha um pol√≠gono ao redor de cada hotspot da categoria 'Agrupado'.")
                    
                    gdf_clusters_reais = gdf_filtrado_base[(gdf_filtrado_base['classificacao'] == 'Agrupado') & (gdf_filtrado_base['cluster'] != -1)]
                    if not gdf_clusters_reais.empty:
                        map_center_hull = [gdf_clusters_reais.latitude.mean(), gdf_clusters_reais.longitude.mean()]
                        m_hull = folium.Map(location=map_center_hull, zoom_start=11)
                        if geometrias_kml_dict:
                            for nome, poligono in geometrias_kml_dict.items():
                                folium.GeoJson(poligono, style_function=lambda x: {'fillColor': 'red', 'color': 'red', 'weight': 2, 'fillOpacity': 0.1}, tooltip=f"√Årea de Risco: {nome}").add_to(m_hull)
                        if kml_laranja_dict:
                            for nome, poligono in kml_laranja_dict.items():
                                if poligono and not poligono.is_empty:
                                    folium.GeoJson(poligono, style_function=lambda x: {'fillColor': 'orange', 'color': 'orange', 'weight': 2, 'fillOpacity': 0.1}, tooltip=f"√Årea Laranja: {nome}").add_to(m_hull)
                        try:
                            hulls = gdf_clusters_reais.dissolve(by='cluster').convex_hull
                            gdf_hulls = gpd.GeoDataFrame(geometry=hulls).reset_index()
                            folium.GeoJson(gdf_hulls, style_function=lambda x: {'color': 'blue', 'weight': 2.5, 'fillColor': 'blue', 'fillOpacity': 0.2}, tooltip=folium.GeoJsonTooltip(fields=['cluster'], aliases=['Hotspot ID:'])).add_to(m_hull)
                            st_folium(m_hull, use_container_width=True, height=700)
                        except Exception as e:
                            st.warning(f"N√£o foi poss√≠vel desenhar os contornos. Erro: {e}")
                    else:
                        st.warning("Nenhum cluster para desenhar.")
            tab_index += 1

            if df_metas is not None:
                with tabs[tab_index]: # Pacotes de Trabalho
                    cos_simulados = gdf_alocados_final['centro_operativo'].unique() if not gdf_alocados_final.empty else []
                    metas_filtradas = df_metas[df_metas['centro_operativo'].isin(cos_simulados)]
                    
                    st.subheader("Painel de Simula√ß√£o")
                    if not metas_filtradas.empty:
                        equipes_disponiveis = metas_filtradas['equipes'].sum()
                        meta_diaria_total = metas_filtradas['meta_di√°ria'].sum()
                        metas_filtradas['expectativa_execucao'] = metas_filtradas['equipes'] * metas_filtradas['produ√ß√£o']
                        expectativa_total = metas_filtradas['expectativa_execucao'].sum()
                        
                        servicos_agrupados_para_pacotes = len(gdf_filtrado_base[gdf_filtrado_base['classificacao'] == 'Agrupado'])
                        servicos_alocados = len(gdf_alocados_final)
                        pacotes_criados = gdf_alocados_final['pacote_id'].nunique() if not gdf_alocados_final.empty else 0
                        servicos_excedentes = len(gdf_excedentes_final)

                        aderencia_meta = (servicos_alocados / meta_diaria_total * 100) if meta_diaria_total > 0 else 0
                        ocupacao_equipes = (pacotes_criados / equipes_disponiveis * 100) if equipes_disponiveis > 0 else 0

                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.markdown("##### Par√¢metros de Planejamento")
                            st.metric("Equipes Dispon√≠veis", f"{int(equipes_disponiveis)}")
                            st.metric("Meta Di√°ria (CO)", f"{int(meta_diaria_total)}")
                            st.metric("Expectativa de Execu√ß√£o", f"{int(expectativa_total)}")
                        with col2:
                            st.markdown("##### Resultado da Simula√ß√£o")
                            st.metric("Servi√ßos Agrupados (Roteiriz√°veis)", f"{servicos_agrupados_para_pacotes}")
                            st.metric("Servi√ßos Alocados", f"{servicos_alocados}")
                            st.metric("Pacotes Criados", f"{pacotes_criados}")
                            st.metric("Servi√ßos Excedentes", f"{servicos_excedentes}")
                        with col3:
                            st.markdown("##### An√°lise de Desempenho")
                            st.metric("Ader√™ncia √† Meta", f"{aderencia_meta:.1f}%")
                            st.metric("Ocupa√ß√£o das Equipes", f"{ocupacao_equipes:.1f}%")
                    
                    st.markdown("---")
                    
                    if not gdf_filtrado_base.empty:
                        map_center_pacotes = [gdf_filtrado_base.latitude.mean(), gdf_filtrado_base.longitude.mean()]
                        m_pacotes = folium.Map(location=map_center_pacotes, zoom_start=10)
                        cores_co = {co: color for co, color in zip(gdf_filtrado_base['centro_operativo'].unique(), ['blue', 'green', 'purple', 'orange', 'darkred', 'red', 'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue', 'lightgreen', 'pink', 'lightblue', 'lightgray', 'black'])}
                        if geometrias_kml_dict:
                            for nome, poligono in geometrias_kml_dict.items():
                                folium.GeoJson(poligono, style_function=lambda x: {'fillColor': 'red', 'color': 'red', 'weight': 2, 'fillOpacity': 0.1}, tooltip=f"√Årea de Risco: {nome}").add_to(m_pacotes)
                        if kml_laranja_dict:
                            for nome, poligono in kml_laranja_dict.items():
                                if poligono and not poligono.is_empty:
                                    folium.GeoJson(poligono, style_function=lambda x: {'fillColor': 'orange', 'color': 'orange', 'weight': 2, 'fillOpacity': 0.1}, tooltip=f"√Årea Laranja: {nome}").add_to(m_pacotes)

                        if not gdf_alocados_final.empty:
                            gdf_hulls_pacotes = gdf_alocados_final.dissolve(by=['centro_operativo', 'pacote_id']).convex_hull.reset_index()
                            gdf_hulls_pacotes = gdf_hulls_pacotes.rename(columns={0: 'geometry'}).set_geometry('geometry')
                            
                            counts_pacotes = gdf_alocados_final.groupby(['centro_operativo', 'pacote_id']).size().rename('contagem').reset_index()
                            gdf_hulls_pacotes = gdf_hulls_pacotes.merge(counts_pacotes, on=['centro_operativo', 'pacote_id'])
                            
                            gdf_hulls_pacotes_proj = gdf_hulls_pacotes.to_crs("EPSG:3857")
                            gdf_hulls_pacotes['area_km2'] = (gdf_hulls_pacotes_proj.geometry.area / 1_000_000).round(2)
                            
                            folium.GeoJson(
                                gdf_hulls_pacotes,
                                style_function=lambda feature: {'color': cores_co.get(feature['properties']['centro_operativo'], 'gray'), 'weight': 2.5, 'fillColor': cores_co.get(feature['properties']['centro_operativo'], 'gray'), 'fillOpacity': 0.25},
                                tooltip=folium.GeoJsonTooltip(fields=['centro_operativo', 'pacote_id', 'contagem', 'area_km2'], aliases=['CO:', 'Pacote:', 'N¬∫ de Servi√ßos:', '√Årea (km¬≤):'], localize=True, sticky=True)
                            ).add_to(m_pacotes)
                            
                            for _, row in gdf_alocados_final.iterrows():
                                folium.CircleMarker(
                                    location=[row['latitude'], row['longitude']],
                                    radius=3,
                                    color=cores_co.get(row['centro_operativo'], 'gray'),
                                    fill=True,
                                    fill_opacity=1,
                                    popup=f"Pacote: {row['pacote_id']}"
                                ).add_to(m_pacotes)
                        
                        st_folium(m_pacotes, use_container_width=True, height=700)
                    else:
                        st.info("Nenhum pacote de trabalho para simular.")
                tab_index += 1
            
            with tabs[tab_index]: # Previs√£o do Tempo
                st.subheader("Painel de Previs√£o do Tempo e Conting√™ncia")
                api_key = st.secrets.get("OPENWEATHER_API_KEY")

                if not api_key:
                    st.error("Chave da API OpenWeatherMap n√£o encontrada. Por favor, configure-a nos 'secrets' do Streamlit como 'OPENWEATHER_API_KEY'.")
                else:
                    centroids = gdf_filtrado_base.dissolve(by='centro_operativo').centroid
                    co_coords = {co: (point.y, point.x) for co, point in centroids.items()}
                    
                    for co, coords in co_coords.items():
                        with st.expander(f"**{co}**"):
                            forecast_data = get_weather_forecast(coords[0], coords[1], api_key)
                            if isinstance(forecast_data, list):
                                cols = st.columns(len(forecast_data))
                                for i, day in enumerate(forecast_data):
                                    with cols[i]:
                                        st.markdown(f"**{day['date']}**")
                                        st.image(day['icon'], width=60)
                                        st.markdown(day['condition'])
                                        st.markdown(f"Vento: **{day['wind_speed_kmh']} km/h**")
                                        st.markdown(get_operational_status(day['condition'], day['wind_speed_kmh']))
                            else:
                                st.warning(f"N√£o foi poss√≠vel obter a previs√£o para {co}. Erro: {forecast_data}")
            tab_index += 1

            with tabs[tab_index]: # Metodologia
                st.subheader("As Metodologias por Tr√°s da An√°lise")
                st.markdown("""
                Esta ferramenta utiliza uma combina√ß√£o de algoritmos geoespaciais e de aprendizado de m√°quina para fornecer insights sobre a distribui√ß√£o de servi√ßos.
                - **Detec√ß√£o de √Åreas de Exce√ß√£o (KML/KMZ):** O script primeiramente l√™ todos os arquivos `.kml` e `.kmz` da pasta do projeto para identificar pol√≠gonos de √°reas de risco ou ilhas log√≠sticas. Uma "√Årea Laranja" de 120 metros √© criada ao redor destas √°reas como uma zona de pr√©-risco, que pode ser desativada para √°reas espec√≠ficas na barra lateral. Servi√ßos dentro de ambas as zonas s√£o classificados separadamente e exclu√≠dos da an√°lise de clusteriza√ß√£o.
                - **Detec√ß√£o de Hotspots (DBSCAN):** Nos servi√ßos restantes, o DBSCAN √© usado para encontrar "hotspots" - √°reas de alta concentra√ß√£o de servi√ßos. Ele agrupa pontos densamente pr√≥ximos e marca como "dispersos" os que est√£o isolados.
                - **Simula√ß√£o de Pacotes (Ranking de Densidade):** A l√≥gica para criar pacotes de trabalho prioriza a efici√™ncia. Os hotspots ("Agrupados") s√£o transformados em "pacotes candidatos". Se um hotspot for muito grande para uma √∫nica equipe, ele √© subdividido de forma inteligente. Todos os candidatos s√£o ent√£o ranqueados pela sua densidade (servi√ßos por km¬≤), e os melhores s√£o atribu√≠dos √†s equipes dispon√≠veis, respeitando o n√∫mero de **Servi√ßos Designados**.
                """)
                st.subheader("Perguntas Frequentes (FAQ)")
                st.markdown("""
                - **Qual a diferen√ßa entre as colunas da planilha de metas?**
                  - **`Produ√ß√£o`**: √â a meta de servi√ßos *executados com sucesso* que uma equipe deve atingir. √â usada para calcular a "Expectativa de Execu√ß√£o".
                  - **`Servi√ßos Designados`**: √â a quantidade total de servi√ßos que devem ser atribu√≠dos a uma equipe para o dia. Este n√∫mero √© geralmente maior que a 'Produ√ß√£o' para compensar a **improdutividade** (ex: cliente ausente). A ferramenta usa os **'Servi√ßos Designados'** para definir o tamanho m√°ximo de um pacote de trabalho.
                  - **`Meta Di√°ria`**: √â a meta total do Centro Operativo. √â usada para calcular a m√©trica de "Ader√™ncia √† Meta".

                - **Qual a estrat√©gia usada para formar os pacotes de trabalho?**
                  - A ferramenta adota uma estrat√©gia de **"Ranking de Densidade"**. Ela primeiro identifica todas as √°reas de alta concentra√ß√£o de servi√ßos (hotspots). Em seguida, calcula a densidade de cada uma e cria um ranking. Os pacotes s√£o atribu√≠dos √†s equipes come√ßando pelos hotspots mais densos, garantindo a m√°xima efici√™ncia de deslocamento.

                - **O que acontece se um 'hotspot' for muito grande para uma √∫nica equipe?**
                  - Se um hotspot cont√©m mais servi√ßos do que o valor em 'Servi√ßos Designados', a ferramenta aplica um m√©todo de **"descascamento" (peeling)**: ela "recorta" pacotes de tamanho perfeito de dentro do hotspot, um de cada vez, at√© que todos os servi√ßos sejam alocados em pacotes que respeitem o limite da equipe.

                - **Por que alguns servi√ßos ficam como "dispersos"?** - Um servi√ßo √© considerado disperso se ele n√£o estiver dentro de uma √°rea de risco/laranja e n√£o tiver um n√∫mero m√≠nimo de vizinhos (`M√≠nimo de Pontos por Cluster`) dentro de um raio de busca (`Raio do Cluster`).

                - **O que significa um servi√ßo "excedente" na simula√ß√£o?** - S√£o todos os servi√ßos que n√£o foram alocados em um pacote. Isso inclui os servi√ßos **Dispersos**, os em **√Årea de Risco**, os em **√Årea Laranja**, e os **Agrupados** que n√£o entraram no ranking dos melhores pacotes (seja por baixa densidade ou por falta de equipes dispon√≠veis).
                """)
        else:
            st.warning("Nenhum dado para exibir com os filtros atuais.")
else:
    st.info("Aguardando o upload de um arquivo para iniciar a an√°lise.")
